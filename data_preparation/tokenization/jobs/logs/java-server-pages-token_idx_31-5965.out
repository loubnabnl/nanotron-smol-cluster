START TIME: Wed Mar 29 01:06:11 UTC 2023
FULL_OUT_PATH is: /fsx/loubna/data/tokenized_stack_no_pii/code/java-server-pages
/fsx/loubna/code/Megatron-LM/tools/preprocess_data.py --input /fsx/loubna/data/stack_march_no_pii_json/java-server-pages --output-prefix /fsx/loubna/data/tokenized_stack_no_pii/code/java-server-pages/gpt2-preprocessed --tokenizer-type TokenizerFromFile --tokenizer-file /fsx/loubna/data/tokenizer/tokenizer-the-stack-march-sample-v3-no-prefix-spaces/tokenizer.json --dataset-impl mmap --append-eod --json-keys content --workers 64 --chunk-size 100 --log-interval 1000
[H[2J[3J> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
> building TokenizerFromFile tokenizer ...
> building TokenizerFromFile tokenizer ...
> building TokenizerFromFile tokenizer ...
> building TokenizerFromFile tokenizer ...
> building TokenizerFromFile tokenizer ...
> building TokenizerFromFile tokenizer ...
> building TokenizerFromFile tokenizer ...
> building TokenizerFromFile tokenizer ...
> building TokenizerFromFile tokenizer ...
> building TokenizerFromFile tokenizer ...
> building TokenizerFromFile tokenizer ...
> building TokenizerFromFile tokenizer ...
> building TokenizerFromFile tokenizer ...
> building TokenizerFromFile tokenizer ...
> building TokenizerFromFile tokenizer ...
> building TokenizerFromFile tokenizer ...
> building TokenizerFromFile tokenizer ...
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
> building TokenizerFromFile tokenizer ...
> building TokenizerFromFile tokenizer ...
> building TokenizerFromFile tokenizer ...
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
> building TokenizerFromFile tokenizer ...
> building TokenizerFromFile tokenizer ...
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
> building TokenizerFromFile tokenizer ...
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
 > padded vocab (size: 49152) with 0 dummy tokens (new size: 49152)
Processed 1000 documents (705.603607368296 docs/s, 0.0006729160379107437 MB/s).
Processed 2000 documents (1089.0747417497337 docs/s, 0.0010386226098534905 MB/s).
Processed 3000 documents (1234.9283318467897 docs/s, 0.0011777194326846978 MB/s).
Processed 4000 documents (1254.0600952929885 docs/s, 0.0011959649041108976 MB/s).
Processed 5000 documents (1383.7328360613833 docs/s, 0.0013196304665197213 MB/s).
Processed 6000 documents (1497.1028305530806 docs/s, 0.001427748518517571 MB/s).
Processed 7000 documents (1418.8359313800584 docs/s, 0.0013531073869515022 MB/s).
Processed 8000 documents (1483.4096904742885 docs/s, 0.001414689722513474 MB/s).
Processed 9000 documents (1497.5608380162935 docs/s, 0.0014281853084719596 MB/s).
Processed 10000 documents (1523.2334922637585 docs/s, 0.0014526686594617448 MB/s).
Processed 11000 documents (1571.3991345840175 docs/s, 0.0014986029954757857 MB/s).
Processed 12000 documents (1597.0792145026417 docs/s, 0.0015230934281374375 MB/s).
Processed 13000 documents (1612.4154978916094 docs/s, 0.0015377192477146239 MB/s).
Processed 14000 documents (1460.5743041676008 docs/s, 0.001392912201087571 MB/s).
Processed 15000 documents (1511.6115354870678 docs/s, 0.0014415850977774313 MB/s).
Processed 16000 documents (1535.190520574509 docs/s, 0.00146407177026225 MB/s).
Processed 17000 documents (1562.2677010595758 docs/s, 0.0014898945818515546 MB/s).
Processed 18000 documents (1589.2884351123168 docs/s, 0.0015156635619280976 MB/s).
Processed 19000 documents (1606.48035175592 docs/s, 0.0015320590512808991 MB/s).
Processed 20000 documents (1612.3253918865125 docs/s, 0.001537633315931809 MB/s).
Processed 21000 documents (1616.0316687986156 docs/s, 0.001541167897032371 MB/s).
Processed 22000 documents (1304.9735379039066 docs/s, 0.0012445197466887537 MB/s).
Processed 23000 documents (1288.3676613159475 docs/s, 0.0012286831486854053 MB/s).
Processed 24000 documents (1288.350346100033 docs/s, 0.0012286666356087046 MB/s).
Processed 25000 documents (1294.5113265913997 docs/s, 0.001234542204467201 MB/s).
Processed 26000 documents (1300.361541893978 docs/s, 0.0012401214045467167 MB/s).
Processed 27000 documents (1149.82092652779 docs/s, 0.0010965546860959912 MB/s).
Processed 28000 documents (1169.8693027394188 docs/s, 0.0011156743075746716 MB/s).
Processed 29000 documents (1193.0138587745653 docs/s, 0.001137746676230016 MB/s).
Processed 30000 documents (1214.1149360078412 docs/s, 0.0011578702316358959 MB/s).
Processed 31000 documents (1222.2667600748925 docs/s, 0.0011656444168805051 MB/s).
Processed 32000 documents (1240.2185645473633 docs/s, 0.0011827645917390473 MB/s).
Processed 33000 documents (1249.8592405186191 docs/s, 0.0011919586568056289 MB/s).
Processed 34000 documents (1253.3683414787963 docs/s, 0.0011953051962650264 MB/s).
Processed 35000 documents (1262.078492016043 docs/s, 0.0012036118431244306 MB/s).
Processed 36000 documents (1266.0886602317694 docs/s, 0.0012074362375562376 MB/s).
Processed 37000 documents (1269.9720355205347 docs/s, 0.0012111397128300998 MB/s).
Processed 38000 documents (1043.8789909364073 docs/s, 0.0009955205830921242 MB/s).
Processed 39000 documents (1055.868450208792 docs/s, 0.0010069546224677963 MB/s).
Processed 40000 documents (1066.5402913957548 docs/s, 0.0010171320833165692 MB/s).
Processed 41000 documents (1084.1958737431885 docs/s, 0.0010339697587425122 MB/s).
Processed 42000 documents (1101.1697965293874 docs/s, 0.001050157352952373 MB/s).
Processed 43000 documents (1109.6733638026446 docs/s, 0.001058266986658711 MB/s).
Processed 44000 documents (1125.3088679931343 docs/s, 0.0010731781654292434 MB/s).
Processed 45000 documents (1141.8809857968722 docs/s, 0.001088982568547127 MB/s).
Processed 46000 documents (1155.617294006085 docs/s, 0.0011020825328884936 MB/s).
Processed 47000 documents (1170.9604930605374 docs/s, 0.0011167149477582334 MB/s).
Processed 48000 documents (1185.1332294372298 docs/s, 0.0011302311224338816 MB/s).
Processed 49000 documents (1201.3855834253284 docs/s, 0.0011457305750134739 MB/s).
Processed 50000 documents (1219.087798943336 docs/s, 0.001162612723296486 MB/s).
Processed 51000 documents (1236.8288151403417 docs/s, 0.0011795318747905175 MB/s).
Processed 52000 documents (1252.9002713105008 docs/s, 0.001194858809767247 MB/s).
Processed 53000 documents (1271.6895822727963 docs/s, 0.0012127776930549586 MB/s).
Processed 54000 documents (1291.4043721357446 docs/s, 0.0012315791818005987 MB/s).
Processed 55000 documents (1311.0374945459803 docs/s, 0.0012503027863941005 MB/s).
Processed 56000 documents (1330.43447757431 docs/s, 0.0012688011909239864 MB/s).
Processed 57000 documents (1349.8156871058866 docs/s, 0.001287284552675139 MB/s).
Processed 58000 documents (1369.059505515466 docs/s, 0.0013056368880419408 MB/s).
Processed 59000 documents (1388.5996947856363 docs/s, 0.001324271864686619 MB/s).
Processed 60000 documents (1407.8053118847329 docs/s, 0.0013425877684447602 MB/s).
Processed 61000 documents (1426.7408401695204 docs/s, 0.0013606460954375462 MB/s).
Processed 62000 documents (1445.7490238226524 docs/s, 0.0013787737119890712 MB/s).
Processed 63000 documents (1464.4619140141144 docs/s, 0.001396619714750399 MB/s).
Processed 64000 documents (1483.4946134180204 docs/s, 0.0014147707113437847 MB/s).
Processed 65000 documents (1502.5218724510964 docs/s, 0.0014329165195952382 MB/s).
Processed 66000 documents (1521.3711951020766 docs/s, 0.0014508926344891325 MB/s).
Processed 67000 documents (1539.6611498533691 docs/s, 0.0014683352945836726 MB/s).
Processed 68000 documents (1557.756916377824 docs/s, 0.0014855927623537292 MB/s).
Processed 69000 documents (1575.8774888571702 docs/s, 0.0015028738869258596 MB/s).
Processed 70000 documents (1593.806979470732 docs/s, 0.0015199727816302604 MB/s).
Processed 71000 documents (1612.2182532383736 docs/s, 0.0015375311405547844 MB/s).
Processed 72000 documents (1630.1891603128367 docs/s, 0.0015546695330742233 MB/s).
Processed 73000 documents (1648.5673237237609 docs/s, 0.0015721963155019387 MB/s).
Processed 74000 documents (1666.5063634912615 docs/s, 0.0015893043169891944 MB/s).
Processed 75000 documents (1683.5495907577144 docs/s, 0.0016055580051018853 MB/s).
Processed 76000 documents (1700.6498598694359 docs/s, 0.0016218660925573691 MB/s).
Processed 77000 documents (1717.8802958079525 docs/s, 0.0016382983167724156 MB/s).
Processed 78000 documents (1734.9799878869062 docs/s, 0.0016546058539265692 MB/s).
Processed 79000 documents (1752.0261836823952 docs/s, 0.0016708623730491592 MB/s).
Processed 80000 documents (1769.2648215083182 docs/s, 0.0016873024191935712 MB/s).
Processed 81000 documents (1786.1795044487926 docs/s, 0.0017034335178840567 MB/s).
Processed 82000 documents (1803.2806730014988 docs/s, 0.0017197424631133068 MB/s).
Processed 83000 documents (1819.9846706647434 docs/s, 0.0017356726366660532 MB/s).
Processed 84000 documents (1836.4484834088455 docs/s, 0.0017513737520302253 MB/s).
Processed 85000 documents (1853.4607375617295 docs/s, 0.0017675979018800063 MB/s).
Processed 86000 documents (1869.6808938401148 docs/s, 0.001783066648330798 MB/s).
Processed 87000 documents (1885.9557686897915 docs/s, 0.0017985875784776607 MB/s).
Processed 88000 documents (1902.079728433011 docs/s, 0.0018139645847635374 MB/s).
Processed 89000 documents (1918.3216481321642 docs/s, 0.0018294540864297526 MB/s).
Processed 90000 documents (1934.752051403004 docs/s, 0.0018451233400373498 MB/s).
Processed 91000 documents (1950.7748382749392 docs/s, 0.0018604038603543655 MB/s).
Processed 92000 documents (1966.8755791245771 docs/s, 0.0018757587233777782 MB/s).
Processed 93000 documents (1983.0413504783314 docs/s, 0.0018911756043227495 MB/s).
Processed 94000 documents (1998.3283290047366 docs/s, 0.001905754403118836 MB/s).
Processed 95000 documents (2013.4475185541282 docs/s, 0.0019201731858769686 MB/s).
Processed 96000 documents (2029.0894391917795 docs/s, 0.0019350904838483615 MB/s).
Processed 97000 documents (2044.666804874968 docs/s, 0.0019499462174176864 MB/s).
Processed 98000 documents (2059.7588953081745 docs/s, 0.001964339156444716 MB/s).
Processed 99000 documents (2074.9031696087886 docs/s, 0.001978781861885823 MB/s).
Processed 100000 documents (2090.553252281304 docs/s, 0.0019937069437802354 MB/s).
Processed 101000 documents (2106.061767288854 docs/s, 0.0020084970162285365 MB/s).
Processed 102000 documents (2121.0785142567624 docs/s, 0.0020228181021278023 MB/s).
Processed 103000 documents (2135.5035074910315 docs/s, 0.0020365748476896587 MB/s).
Processed 104000 documents (2150.4820101467453 docs/s, 0.0020508594609706357 MB/s).
Processed 105000 documents (2165.477943778891 docs/s, 0.002065160697726146 MB/s).
Processed 106000 documents (2180.235060758803 docs/s, 0.00207923418117409 MB/s).
Processed 107000 documents (2195.5053993523934 docs/s, 0.0020937971108936247 MB/s).
Processed 108000 documents (2210.3276308061286 docs/s, 0.002107932692342881 MB/s).
Processed 109000 documents (2224.8716879792937 docs/s, 0.0021218029861252725 MB/s).
Processed 110000 documents (2239.3291014792585 docs/s, 0.002135590650061854 MB/s).
Processed 111000 documents (2254.1722251605584 docs/s, 0.002149746155891951 MB/s).
Processed 112000 documents (2268.488046270387 docs/s, 0.0021633987868026608 MB/s).
Processed 113000 documents (2282.7112215871703 docs/s, 0.0021769630638000205 MB/s).
Processed 114000 documents (2297.0132489082803 docs/s, 0.0021906025399287036 MB/s).
Processed 115000 documents (2311.077501901454 docs/s, 0.002204015256787733 MB/s).
Processed 116000 documents (2325.682460299096 docs/s, 0.002217943630503746 MB/s).
Processed 117000 documents (2339.256422464207 docs/s, 0.0022308887695924825 MB/s).
Processed 118000 documents (2353.0654006325135 docs/s, 0.002244058037407411 MB/s).
Processed 119000 documents (2366.6811215413577 docs/s, 0.0022570430007375314 MB/s).
Processed 120000 documents (2380.3634476055295 docs/s, 0.002270091483693628 MB/s).
Processed 121000 documents (2393.8997541745966 docs/s, 0.0022830007116075484 MB/s).
Processed 122000 documents (2407.262784029545 docs/s, 0.0022957446899695825 MB/s).
Processed 123000 documents (2421.139112049962 docs/s, 0.0023089781876086827 MB/s).
Processed 124000 documents (2434.4274661080735 docs/s, 0.0023216509495812164 MB/s).
Processed 125000 documents (2447.9981442040435 docs/s, 0.0023345929567375598 MB/s).
Processed 126000 documents (2461.251783902607 docs/s, 0.002347232612516982 MB/s).
Processed 127000 documents (2474.3108525670714 docs/s, 0.0023596867108984674 MB/s).
Processed 128000 documents (2487.5216945977036 docs/s, 0.0023722855516411815 MB/s).
Processed 129000 documents (2500.741482159649 docs/s, 0.0023848929235073557 MB/s).
Processed 130000 documents (2514.350430464034 docs/s, 0.002397871427978548 MB/s).
Processed 131000 documents (2527.2737092478055 docs/s, 0.0024101960270383888 MB/s).
Processed 132000 documents (2539.5216334192323 docs/s, 0.00242187655774997 MB/s).
Processed 133000 documents (2552.2794166077633 docs/s, 0.0024340433279111512 MB/s).
Processed 134000 documents (2565.330748452281 docs/s, 0.002446490047886163 MB/s).
Processed 135000 documents (2577.797893595675 docs/s, 0.0024583796440083264 MB/s).
Processed 136000 documents (2590.815665855439 docs/s, 0.002470794359069289 MB/s).
Processed 137000 documents (2603.7584607135327 docs/s, 0.002483137570107968 MB/s).
Processed 138000 documents (2616.439247539432 docs/s, 0.002495230910815651 MB/s).
Processed 139000 documents (2628.8814010568863 docs/s, 0.0025070966730660308 MB/s).
Processed 140000 documents (2640.961694092543 docs/s, 0.002518617338268798 MB/s).
Processed 141000 documents (2652.1121234284637 docs/s, 0.0025292512163433683 MB/s).
Processed 142000 documents (2664.4278460316154 docs/s, 0.002540996404677978 MB/s).
Processed 143000 documents (2676.9484328468384 docs/s, 0.002552936966749991 MB/s).
Processed 144000 documents (2689.1143042701774 docs/s, 0.00256453924586313 MB/s).
Processed 145000 documents (2701.127955077537 docs/s, 0.002575996356084382 MB/s).
Processed 146000 documents (2713.070651205353 docs/s, 0.0025873857986501245 MB/s).
Processed 147000 documents (2724.4920346471367 docs/s, 0.0025982780786963813 MB/s).
Processed 148000 documents (2736.750063043739 docs/s, 0.0026099682455479993 MB/s).
Processed 149000 documents (2749.1393929245924 docs/s, 0.0026217836312528537 MB/s).
Processed 150000 documents (2761.038012906608 docs/s, 0.00263313103953038 MB/s).
Processed 151000 documents (2772.3902578977754 docs/s, 0.002643957384012008 MB/s).
Processed 152000 documents (2783.661769822858 docs/s, 0.002654706735442026 MB/s).
Processed 153000 documents (2795.2590261947125 docs/s, 0.0026657667409846425 MB/s).
Processed 154000 documents (2805.948417898912 docs/s, 0.0026759609393109435 MB/s).
Processed 155000 documents (2817.8451231047316 docs/s, 0.0026873065215155902 MB/s).
Processed 156000 documents (2829.156940609587 docs/s, 0.0026980943113418454 MB/s).
Processed 157000 documents (2840.462365277255 docs/s, 0.002708876004483466 MB/s).
Processed 158000 documents (2851.899113180776 docs/s, 0.0027197829372222673 MB/s).
Processed 159000 documents (2863.3694747958293 docs/s, 0.0027307219264944356 MB/s).
Processed 160000 documents (2874.70049609449 docs/s, 0.0027415280304856206 MB/s).
Processed 161000 documents (2886.0042069371043 docs/s, 0.0027523080891963046 MB/s).
Processed 162000 documents (2896.9761271581037 docs/s, 0.00276277172771273 MB/s).
Processed 163000 documents (2908.258063976572 docs/s, 0.0027735310210958214 MB/s).
Processed 164000 documents (2918.99741232187 docs/s, 0.002783772861787672 MB/s).
Processed 165000 documents (2930.725885954576 docs/s, 0.0027949580058618316 MB/s).
Processed 166000 documents (2942.3311193058703 docs/s, 0.0028060256188448623 MB/s).
Processed 167000 documents (2953.4405895648697 docs/s, 0.002816620435299749 MB/s).
Processed 168000 documents (2964.210369880301 docs/s, 0.0028268912981799137 MB/s).
Processed 169000 documents (2975.042243645118 docs/s, 0.0028372213779879743 MB/s).
Processed 170000 documents (2985.925316824845 docs/s, 0.0028476002853630496 MB/s).
Processed 171000 documents (2997.2840124519685 docs/s, 0.002858432781650513 MB/s).
Processed 172000 documents (3007.949072009389 docs/s, 0.002868603775033368 MB/s).
Processed 173000 documents (3018.5359129764943 docs/s, 0.002878700173355574 MB/s).
Processed 174000 documents (3029.500608478864 docs/s, 0.002889156921843399 MB/s).
Processed 175000 documents (3040.5242284980945 docs/s, 0.002899669865129561 MB/s).
Processed 176000 documents (3051.512322963632 docs/s, 0.0029101489286075897 MB/s).
Processed 177000 documents (3060.938713595553 docs/s, 0.0029191386352496653 MB/s).
Processed 178000 documents (3071.6276111578054 docs/s, 0.0029293323623254828 MB/s).
Processed 179000 documents (3081.9386071913627 docs/s, 0.002939165694419253 MB/s).
Processed 180000 documents (3092.72152364771 docs/s, 0.0029494490848996258 MB/s).
Processed 181000 documents (3102.763633408772 docs/s, 0.002959025987061283 MB/s).
Processed 182000 documents (3112.690590456392 docs/s, 0.002968493071037666 MB/s).
Processed 183000 documents (3122.3616276078997 docs/s, 0.00297771609078207 MB/s).
Processed 184000 documents (3133.1873283203895 docs/s, 0.0029880402835086722 MB/s).
Processed 185000 documents (3143.3999979615096 docs/s, 0.0029977798442473503 MB/s).
Processed 186000 documents (3153.8972551919846 docs/s, 0.003007790808860764 MB/s).
Processed 187000 documents (3163.892550059931 docs/s, 0.003017323064861232 MB/s).
Processed 188000 documents (3173.789009098842 docs/s, 0.003026761063670008 MB/s).
Processed 189000 documents (3184.0784688601702 docs/s, 0.003036573857174082 MB/s).
Processed 190000 documents (3193.8462779013967 docs/s, 0.0030458891657842604 MB/s).
Processed 191000 documents (3203.5903857521416 docs/s, 0.0030551818711778084 MB/s).
Processed 192000 documents (3213.759625578933 docs/s, 0.003064880014017995 MB/s).
Processed 193000 documents (3223.3460946275754 docs/s, 0.0030740223833347086 MB/s).
Processed 194000 documents (3232.649328930711 docs/s, 0.0030828946389491185 MB/s).
Processed 195000 documents (3242.3488612429383 docs/s, 0.0030921448337964423 MB/s).
Processed 196000 documents (3252.0351714488506 docs/s, 0.0031013824190605646 MB/s).
Processed 197000 documents (3261.7210465275384 docs/s, 0.0031106195893550286 MB/s).
Processed 198000 documents (3271.553380515348 docs/s, 0.003119996433749531 MB/s).
Processed 199000 documents (3280.806765118221 docs/s, 0.0031288211489851198 MB/s).
Processed 200000 documents (3290.297920256074 docs/s, 0.0031378726198731176 MB/s).
Processed 201000 documents (3299.7555921584863 docs/s, 0.003146892158659445 MB/s).
Processed 202000 documents (3309.3290948788967 docs/s, 0.003156022162321946 MB/s).
Processed 203000 documents (3318.409035898303 docs/s, 0.0031646814688666373 MB/s).
Processed 204000 documents (3328.2685788117847 docs/s, 0.00317408426171473 MB/s).
Processed 205000 documents (3337.4302715609724 docs/s, 0.0031828215327844357 MB/s).
Processed 206000 documents (3347.196111744078 docs/s, 0.0031921349637451914 MB/s).
Processed 207000 documents (3355.8998747458536 docs/s, 0.003200435518976072 MB/s).
Processed 208000 documents (3365.4318015871104 docs/s, 0.003209525872790442 MB/s).
Processed 209000 documents (3375.5386830002763 docs/s, 0.003219164546013142 MB/s).
Processed 210000 documents (3384.351401391444 docs/s, 0.0032275690092005197 MB/s).
Opening /fsx/loubna/data/stack_march_no_pii_json/java-server-pages
Input is not a jsonl file, will try to load from HF datasets
Vocab size: 49152
Output prefix: /fsx/loubna/data/tokenized_stack_no_pii/code/java-server-pages/gpt2-preprocessed
Time to startup: 0.7799828052520752
END TIME: Wed Mar 29 01:07:36 UTC 2023
